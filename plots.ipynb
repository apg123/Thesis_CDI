{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_cats(data, col):\n",
    "    return data.groupby(col).mean(numeric_only=True)\n",
    "\n",
    "## NOTE: This is an implementation modifying an example from https://stackoverflow.com/questions/32791911/fast-calculation-of-pareto-front-in-python\n",
    "def is_pareto_efficient_simple(data, xcol, ycol, xlowerisbetter=True, ylowerisbetter=False):\n",
    "    if xlowerisbetter:\n",
    "        xcost = data[xcol]\n",
    "    else:\n",
    "        xcost = -data[xcol]\n",
    "    if ylowerisbetter:\n",
    "        ycost = data[ycol]\n",
    "    else:\n",
    "        ycost = -data[ycol]\n",
    "    costs = np.array([xcost, ycost]).T\n",
    "    is_efficient = np.ones(costs.shape[0], dtype = bool)\n",
    "    for i, c in enumerate(costs):\n",
    "        if is_efficient[i]:\n",
    "            is_efficient[is_efficient] = np.any(costs[is_efficient]<c, axis=1)  # Keep any point with a lower cost\n",
    "            is_efficient[i] = True  # And keep self\n",
    "    return is_efficient\n",
    "\n",
    "def plot_across_tol(df, k, method_names, axis1, axis2, xlabel=None, ylabel=None, title=None, reverse_x = False, legend=True):\n",
    "    relevant_k = df[df['k'] == k]\n",
    "\n",
    "    for method in method_names:\n",
    "        data_for_method = relevant_k[relevant_k['name'] == method]\n",
    "        d1 = data_for_method[axis1]\n",
    "        d2 = data_for_method[axis2]\n",
    "\n",
    "        if method in [\"Baseline\", \"DebiasClip\"]:\n",
    "            plt.scatter(d1, d2, label=method)\n",
    "        else:\n",
    "            plt.plot(d1, d2, label=method)\n",
    "    if legend: plt.legend()\n",
    "    if xlabel is not None:\n",
    "        plt.xlabel(xlabel)\n",
    "    else:\n",
    "        plt.xlabel(axis1)\n",
    "    if ylabel is not None:\n",
    "        plt.ylabel(ylabel)\n",
    "    else:\n",
    "        plt.ylabel(axis2)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    else:\n",
    "        plt.title(f\"Graph of {axis2} over {axis1} @ {k}\")\n",
    "    if reverse_x:\n",
    "        plt.gca().invert_xaxis()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "validation = pd.read_pickle('results/occ2-3-29-validation.pkl')\n",
    "\n",
    "methods = validation['name'].unique()\n",
    "print(methods)\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Subgroup Bias']\n",
    "metrics = ['Avg_AbsBias_gender', 'Avg_AbsBias_skintone', 'Avg_Max_MC_Bias']\n",
    "\n",
    "fig, ax = plt.subplots(3, 4, figsize=(10, 7))\n",
    "\n",
    "for i in range(3):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[i, j].set_ylim(0, .75)\n",
    "        ax[i, j].set_xlim(.7, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[i, j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[i, j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for method in methods:\n",
    "            data = validation[(validation['name'] == method) & (validation['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[i, j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Precision'], label=method,  linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.18)\n",
    "fig.show()\n",
    "\n",
    "methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Min_intersectional', 'PBM_intersectional']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', '#bcbd22', '#17becf']\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3))\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Subgroup Bias']\n",
    "metrics = ['Avg_Max_MC_Bias']\n",
    "for i in range(1):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[j].set_ylim(0, .7)\n",
    "        ax[j].set_xlim(.6, 0)\n",
    "        ax[j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for z, method in enumerate(methods):\n",
    "            c = colors[z]\n",
    "            data = validation[(validation['name'] == method) & (validation['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                ax[j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "                bc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Precision')].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                wc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Precision', xlowerisbetter=False, ylowerisbetter=True)].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                ax[j].plot(bc[metric], bc['Avg_Precision'], label='_nolegend_', alpha=.5, c=c)\n",
    "                ax[j].plot(wc[metric], wc['Avg_Precision'], label='_nolegend_', alpha=.5, c=c)\n",
    "\n",
    "        handles, labels = ax[j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.38)\n",
    "fig.show()\n",
    "\n",
    "methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Min_intersectional', 'PBM_intersectional']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', '#bcbd22', '#17becf']\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3))\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Subgroup Bias']\n",
    "metrics = ['Avg_Max_MC_Bias']\n",
    "for i in range(1):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[j].set_ylim(0, .7)\n",
    "        ax[j].set_xlim(.6, 0)\n",
    "        ax[j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[j].set_ylabel('Recall', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for z, method in enumerate(methods):\n",
    "            c = colors[z]\n",
    "            data = validation[(validation['name'] == method) & (validation['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                ax[j].scatter(np.mean(data[metric]), np.mean(data['Avg_Recall']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Recall'], label=method, c=c, linewidth=2.1)\n",
    "                bc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Recall')].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                wc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Recall', xlowerisbetter=False, ylowerisbetter=True)].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                ax[j].plot(bc[metric], bc['Avg_Recall'], label='_nolegend_', alpha=.5, c=c)\n",
    "                ax[j].plot(wc[metric], wc['Avg_Recall'], label='_nolegend_', alpha=.5, c=c)\n",
    "\n",
    "        handles, labels = ax[j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.38)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_res = pd.read_pickle('results/celeba-validation.pkl')\n",
    "\n",
    "all_methods = celeba_res['name'].unique()\n",
    "print(all_methods)\n",
    "\n",
    "core_methods = all_methods\n",
    "print(celeba_res.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Age', 'Subgroup Bias']\n",
    "metrics = ['Avg_AbsBias_Male', 'Avg_AbsBias_Pale_Skin', 'Avg_AbsBias_Young','Avg_Max_MC_Bias']\n",
    "core_methods = all_methods\n",
    "fig, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "        ax[i, j].set_xlim(1, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[i, j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[i, j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for method in core_methods:\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c=c)\n",
    "            else:\n",
    "                avg_c = avg_cats(data, \"tol\")\n",
    "                #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "                pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "                ax[i, j].plot(pareto_points[metric], pareto_points['Avg_Precision'], label=method, linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.show()\n",
    "\n",
    "core_methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Min_intersectional', 'PBM_three_attributes']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', '#bcbd22', '#17becf']\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3))\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Subgroup Bias']\n",
    "metrics = ['Avg_Max_MC_Bias']\n",
    "for i in range(1):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[j].set_ylim(0, .85)\n",
    "        ax[j].set_xlim(.7, 0)\n",
    "        ax[j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[j].set_ylabel('Precision',weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for z, method in enumerate(core_methods):\n",
    "            c = colors[z]\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                ax[j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "                bc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Precision')].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                wc = data.iloc[is_pareto_efficient_simple(data, 'Avg_Max_MC_Bias', 'Avg_Precision', xlowerisbetter=False, ylowerisbetter=True)].sort_values('Avg_Max_MC_Bias', ascending=False)\n",
    "                ax[j].plot(bc[metric], bc['Avg_Precision'], label='_nolegend_', alpha=.5, c=c)\n",
    "                ax[j].plot(wc[metric], wc['Avg_Precision'], label='_nolegend_', alpha=.5, c=c)\n",
    "\n",
    "        handles, labels = ax[j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.34)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('results/giis-3-21.pkl')\n",
    "df2 = pd.read_pickle('results/giis-3-24-CLIP-euc.pkl')\n",
    "df3 = pd.read_pickle('results/giis-cdi_features.pkl')\n",
    "df4 = pd.read_pickle('results/giis-pbm-3-22.pkl')\n",
    "\n",
    "\n",
    "names_to_drop = df2['name'].unique().tolist() + df3['name'].unique().tolist() + df4['name'].unique().tolist()\n",
    "\n",
    "df1_dropped = df1[~df1['name'].isin(names_to_drop)]\n",
    "print(df1_dropped['name'].unique())\n",
    "\n",
    "giis_df = pd.concat([df1_dropped, df2, df3, df4])\n",
    "print(giis_df['name'].unique())\n",
    "\n",
    "pd.to_pickle(giis_df, 'results/giis-complete.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_pickle('results/occ2-3-23.pkl')\n",
    "df2 = pd.read_pickle('results/occ2-3-24-CLIP.pkl')\n",
    "df3 = pd.read_pickle('results/occ2-3-24-eucmethods.pkl')\n",
    "df4 = pd.read_pickle('results/occ2-3-24-skintone.pkl')\n",
    "\n",
    "dfs = [df1, df2, df3, df4]\n",
    "for df in dfs:\n",
    "    print(df['name'].unique()) \n",
    "\n",
    "names_to_drop = df2['name'].unique().tolist() + df3['name'].unique().tolist() + df4['name'].unique().tolist()\n",
    "\n",
    "df1_dropped = df1[~df1['name'].isin(names_to_drop)]\n",
    "print(df1_dropped['name'].unique())\n",
    "\n",
    "occ2_df = pd.concat([df1_dropped, df2, df3, df4])\n",
    "print(occ2_df['name'].unique())\n",
    "\n",
    "pd.to_pickle(occ2_df, 'results/occ2-complete.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2_df = pd.read_pickle('results/occ2-complete.pkl')\n",
    "\n",
    "methods = ['CDI_Sum_gender', 'CDI_Sum_skintone', 'CDI_Sum_intersectional',\n",
    " 'CDI_Sum_3_attr', 'CDI_Sum_4_attr']\n",
    "k = [10, 25, 50, 100]\n",
    "\n",
    "metrics = ['Avg_AbsBias_gender', 'Avg_AbsBias_skintone', 'Avg_Max_MC_Bias']\n",
    "\n",
    "\n",
    "for k in k:\n",
    "    plot_across_tol(occ2_df, k, methods, metrics[0], 'Avg_Precision', xlabel='AbsBias in Gender', ylabel='Precision', title=f'Gender @ {k}', reverse_x=True)\n",
    "    plot_across_tol(occ2_df, k, methods, metrics[1], 'Avg_Precision', xlabel='AbsBias in Skintone', ylabel='Precision', title=f'Skintone @ {k}', reverse_x=True)\n",
    "    plot_across_tol(occ2_df, k, methods, metrics[2], 'Avg_Precision', xlabel='Subgroup Fairness', ylabel='Precision', title=f'Subgroup @ {k}', reverse_x=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giis = pd.read_pickle('results/giis-complete.pkl')\n",
    "\n",
    "print(giis['name'].unique())\n",
    "methods = ['Baseline', 'CDI_Sum_gender', 'CDI_Sum_intersectional', 'CDI_Min_gender', 'CDI_Min_intersectional', 'PBM_gender',\n",
    " 'PBM_intersectional','CLIP_gender', 'CLIP_intersectional', 'DebiasClip']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Recall - Bias @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if j == 0:\n",
    "        ax[i].set_ylabel('Recall', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Gender Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = giis[(giis['name'] == method) & (giis['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_AbsBias_gender']), np.mean(data['Avg_Recall']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_AbsBias_gender'], pareto_points['Avg_Recall'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.42)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2 = pd.read_pickle('results/occ2-complete.pkl')\n",
    "occ2_5 = pd.read_pickle('results/occ2-pbm-five-concepts.pkl')\n",
    "occ2 = pd.concat([occ2, occ2_5])\n",
    "\n",
    "methods = ['Baseline', 'PBM_gender', 'PBM_intersectional',\n",
    " 'PBM_skintone', 'PBM_three_attributes', 'PBM_four_attributes', 'PBM_five_attributes']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision-Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2[(occ2['name'] == method) & (occ2['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "fig.show()\n",
    "\n",
    "occ2 = pd.read_pickle('results/occ2-complete.pkl')\n",
    "\n",
    "methods = ['Baseline', 'CLIP_gender', 'CLIP_skintone', 'CLIP_intersectional', 'CLIP_three_attributes']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.2))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision-Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2[(occ2['name'] == method) & (occ2['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = data\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=5, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_res = pd.read_pickle('results/celeba-3-24.pkl')\n",
    "\n",
    "print(celeba_res['name'].unique())\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Age', 'Subgroup Bias']\n",
    "metrics = ['Avg_AbsBias_Male', 'Avg_AbsBias_Pale_Skin', 'Avg_AbsBias_Young','Avg_Max_MC_Bias']\n",
    "core_methods = ['Baseline', 'CDI_Sum_4_attr', 'CDI_Min_4_attr', 'PBM_four_attributes', 'DebiasClip']\n",
    "fig, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "        ax[i, j].set_xlim(1, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[i, j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[i, j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for method in core_methods:\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c=c)\n",
    "            else:\n",
    "                avg_c = data\n",
    "                #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "                pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "                ax[i, j].plot(pareto_points[metric], pareto_points['Avg_Precision'], label=method, linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_res = pd.read_pickle('results/celeba-validation.pkl')\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Age']\n",
    "metrics = ['Avg_Bias_Male', 'Avg_Bias_Pale_Skin', 'Avg_Bias_Young']\n",
    "core_methods = all_methods\n",
    "fig, ax = plt.subplots(3, 4, figsize=(10, 8))\n",
    "\n",
    "for i in range(3):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        #ax[i, j].set_ylim(0, 1)\n",
    "        #ax[i, j].set_xlim(1, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[i, j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[i, j].set_xlabel(f'Bias for {title}', weight='bold')\n",
    "        for method in core_methods:\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c=c)\n",
    "            else:\n",
    "                avg_c = avg_cats(data, \"tol\")\n",
    "                #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "                pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "                ax[i, j].plot(pareto_points[metric], pareto_points['Avg_Precision'], label=method, linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.16)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_res = pd.read_pickle('results/celeba-validation-white-nonwhite.pkl')\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Age', 'Subgroup Bias']\n",
    "metrics = ['Avg_AbsBias_Male', 'Avg_AbsBias_Pale_Skin', 'Avg_AbsBias_Young','Avg_Max_MC_Bias']\n",
    "core_methods = all_methods\n",
    "fig, ax = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "for i in range(4):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[i, j].set_ylim(0, 1)\n",
    "        ax[i, j].set_xlim(1, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision')\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[i, j].set_xlabel('Max Subgroup Bias')\n",
    "        else:\n",
    "            ax[i, j].set_xlabel(f'AbsBias for {title}')\n",
    "        for method in core_methods:\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=10, c=c)\n",
    "            else:\n",
    "                avg_c = avg_cats(data, \"tol\")\n",
    "                #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "                pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "                ax[i, j].plot(pareto_points[metric], pareto_points['Avg_Precision'], label=method)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3)\n",
    "fig.subplots_adjust(bottom=0.12)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giis = pd.read_pickle('results/giis-complete.pkl')\n",
    "\n",
    "print(giis['name'].unique())\n",
    "methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Sum_gender', 'CDI_TrueConcept', 'CDI_Random', 'CDI_Features']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision - Bias @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('AbsBias for Gender', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = giis[(giis['name'] == method) & (giis['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_AbsBias_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_AbsBias_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_res = pd.read_pickle('results/celeba-3-24.pkl')\n",
    "random = pd.read_pickle('results/celeba-random.pkl')\n",
    "celeba_res = pd.concat([celeba_res, random])\n",
    "print(celeba_res['name'].unique())\n",
    "core_methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_TrueConcept', 'CDI_Random', 'CDI_Features']\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3))\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Subgroup Bias']\n",
    "metrics = ['Avg_Max_MC_Bias']\n",
    "for i in range(1):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[j].set_ylim(0, .85)\n",
    "        ax[j].set_xlim(.7, 0)\n",
    "        ax[j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[j].set_ylabel('Precision',weight='bold', fontsize=12)\n",
    "        if title == 'Subgroup Bias':\n",
    "            ax[j].set_xlabel('Max Subgroup Bias', weight='bold')\n",
    "        else:\n",
    "            ax[j].set_xlabel(f'AbsBias for {title}', weight='bold')\n",
    "        for z, method in enumerate(core_methods):\n",
    "            c = colors[z]\n",
    "            data = celeba_res[(celeba_res['name'] == method) & (celeba_res['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                ax[j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=5, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.32)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giis = pd.read_pickle('results/giis-complete.pkl')\n",
    "#print(giis.head())\n",
    "#print(giis['name'].unique())\n",
    "methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Min_intersectional', \n",
    " 'PBM_intersectional', 'CLIP_intersectional', 'DebiasClip']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision - Acc-Abs-Bias @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.85, 0)\n",
    "    ax[i].grid(True)\n",
    "    if j == 0:\n",
    "        ax[i].set_ylabel('Recall', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Abs Gender Bias in Acc.', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = giis[(giis['name'] == method) & (giis['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_AbsBias_for_Accurate_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_AbsBias_for_Accurate_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=4, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.42)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_pickle('results/occ2-3-29-validation.pkl')\n",
    "\n",
    "methods = validation['name'].unique()\n",
    "print(methods)\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "titles = ['Gender', 'Skin-tone', 'Subgroup Bias']\n",
    "metrics = ['Avg_AbsBias_for_Accurate_gender', 'Avg_AbsBias_for_Accurate_skintone']\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(10, 5.5))\n",
    "\n",
    "for i in range(2):\n",
    "    title = titles[i]\n",
    "    metric = metrics[i]\n",
    "    for j in range(4):\n",
    "        k = ks[j]\n",
    "        ax[i, j].set_title(f'{title} @ {k}', weight='bold')\n",
    "        ax[i, j].set_ylim(0, .75)\n",
    "        ax[i, j].set_xlim(.7, 0)\n",
    "        ax[i, j].grid(True)\n",
    "        if j == 0:\n",
    "            ax[i, j].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "        ax[i, j].set_xlabel(f'AbsBias for {title} in Acc.', weight='bold')\n",
    "        for method in methods:\n",
    "            data = validation[(validation['name'] == method) & (validation['k'] == k)]\n",
    "            if method in ['Baseline', 'DebiasClip']:\n",
    "                if method == 'Baseline':\n",
    "                    c = 'black'\n",
    "                if method == 'DebiasClip':\n",
    "                    c = 'purple'\n",
    "                ax[i, j].scatter(np.mean(data[metric]), np.mean(data['Avg_Precision']), label=method, s=14, c = c)\n",
    "            else:\n",
    "                ax[i, j].plot(avg_cats(data, \"tol\")[metric], avg_cats(data, \"tol\")['Avg_Precision'], label=method,  linewidth=2.1)\n",
    "\n",
    "        handles, labels = ax[i, j].get_legend_handles_labels()\n",
    "\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.subplots_adjust(bottom=0.24)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2 = pd.read_pickle('results/occ2-complete.pkl')\n",
    "\n",
    "methods = ['Baseline', 'CDI_Sum_intersectional', 'CDI_Sum_3_attr', 'CDI_EucSum_3_attr', 'CDI_EucSum_intersectional']\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision-Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2[(occ2['name'] == method) & (occ2['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "fig.show()\n",
    "\n",
    "methods = ['Baseline', 'CDI_Min_intersectional', 'CDI_Min_3_attr', 'CDI_EucMin_3_attr', 'CDI_EucMin_intersectional']\n",
    "\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "fig, ax = plt.subplots(1, 4, figsize=(10, 3.5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision-Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2[(occ2['name'] == method) & (occ2['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c=c)\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles, labels = ax[i].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncols=3, fontsize='large')\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.35)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giis_data = pd.read_csv('datasets/gender_in_image_search/gender_labelled_images.csv')\n",
    "occupations_data = pd.read_csv('datasets/occupations_2/occupations_labels.csv')\n",
    "celeba_data = pd.read_csv('datasets/celeba/list_attr_celeba.csv')\n",
    "celeba_primary_data = pd.read_csv('datasets/celeba/alg_testing.csv')\n",
    "\n",
    "print(f\"GIIS gender: {giis_data['image_gender'].value_counts() / len(giis_data)}\")\n",
    "print(f\"Occupations gender: {occupations_data['gender'].value_counts()/ len(occupations_data)}\")\n",
    "print(f\"Occupations skintone: {occupations_data['skintone'].value_counts() / len(occupations_data)}\")\n",
    "print(f\"CelebA (entire) gender: {celeba_data['Male'].value_counts() / len(celeba_data)}\")\n",
    "print(f\"CelebA (entire) skintone: {celeba_data['Pale_Skin'].value_counts() / len(celeba_data)}\")\n",
    "print(f\"CelebA (entire) age: {celeba_data['Young'].value_counts() / len(celeba_data)}\")\n",
    "print(f\"CelebA (primary) gender: {celeba_primary_data['Male'].value_counts() / len(celeba_primary_data)}\")\n",
    "print(f\"CelebA (primary) skintone: {celeba_primary_data['Pale_Skin'].value_counts() / len(celeba_primary_data)}\")\n",
    "print(f\"CelebA (primary) age: {celeba_primary_data['Young'].value_counts() / len(celeba_primary_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_df = pd.read_pickle('results/giis-complete.pkl')\n",
    "occ2_df = pd.read_pickle('results/occ2-3-29-validation.pkl')\n",
    "celeba_df = pd.read_pickle('results/celeba-validation.pkl')\n",
    "\n",
    "cols = ['name', 'k', 'tol', 'Avg_Precision', 'Avg_AbsBias_gender', 'Avg_Bias_gender']\n",
    "\n",
    "key_models = ['CDI_Sum_intersectional', 'CDI_Min_intersectional']\n",
    "tols = [.02]\n",
    "gs_df1 = gs_df[gs_df['k'].isin([25])]\n",
    "gs_df1 = gs_df1[gs_df1['name'].isin(key_models)]\n",
    "gs_df1 = gs_df1[gs_df1['tol'].isin(tols)][cols]\n",
    "\n",
    "\n",
    "gs_df2 = gs_df[gs_df['k'].isin([25])]\n",
    "gs_df2 = gs_df2[gs_df2['name'] == 'Baseline'][cols]\n",
    "\n",
    "\n",
    "gs_df3 = gs_df[gs_df['k'].isin([25])]\n",
    "gs_df3 = gs_df3[gs_df3['name'].isin(['DebiasClip', 'PBM_intersectional'])][cols]\n",
    "gs_df3 = gs_df3[gs_df3['tol'] == 0]\n",
    "\n",
    "\n",
    "gs_df4 = gs_df[gs_df['k'].isin([25])]\n",
    "gs_df4 = gs_df4[gs_df4['name'] == 'CLIP_intersectional'][cols]\n",
    "gs_df4 = gs_df4[gs_df4['tol'] == 200]\n",
    "print(gs_df4)\n",
    "\n",
    "gs = pd.concat([gs_df2, gs_df1, gs_df3, gs_df4])\n",
    "print(gs)\n",
    "gs.to_csv('results/giis-table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2_c = pd.read_pickle('results/occ2-extra_concepts.pkl')\n",
    "\n",
    "print(occ2_c['name'].unique())\n",
    "print(occ2_c['k'].unique())\n",
    "\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [25, 50]\n",
    "\n",
    "methods = ['Baseline', 'CDI_Min_3_attr', 'CDI_Min_6_attr', 'CDI_Min_8_attr']\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6.))\n",
    "q = 0\n",
    "c = 0\n",
    "for i, k in enumerate(ks):\n",
    "    ax[q, i].set_title(f'Precision - Bias @ {k}', weight='bold')\n",
    "    ax[q, i].set_ylim(0, .7)\n",
    "    ax[q, i].set_xlim(.8, 0)\n",
    "    ax[q, i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[q, i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[q, i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2_c[(occ2_c['name'] == method) & (occ2_c['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[q, i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[q, i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles1, labels1 = ax[q, i].get_legend_handles_labels()\n",
    "\n",
    "methods = ['Baseline', 'CDI_Sum_3_attr', 'CDI_Sum_6_attr', 'CDI_Sum_8_attr']\n",
    "q = 1\n",
    "for i, k in enumerate(ks):\n",
    "    ax[q, i].set_title(f'Precision - Bias @ {k}', weight='bold')\n",
    "    ax[q, i].set_ylim(0, .7)\n",
    "    ax[q, i].set_xlim(.8, 0)\n",
    "    ax[q, i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[q, i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[q, i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[3 + j]\n",
    "        data = occ2_c[(occ2_c['name'] == method) & (occ2_c['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[q, i].scatter(np.mean(data['Avg_Max_MC_Bias']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[q, i].plot(pareto_points['Avg_Max_MC_Bias'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles2, labels2 = ax[q, i].get_legend_handles_labels()\n",
    "\n",
    "handles1 += handles2[1:]\n",
    "labels1 += labels2[1:]\n",
    "\n",
    "fig.legend(handles1, labels1, loc='lower center', ncols=3, fontsize=11)\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2_c = pd.read_pickle('results/occ2-extra_concepts.pkl')\n",
    "\n",
    "print(occ2_c['name'].unique())\n",
    "print(occ2_c['k'].unique())\n",
    "\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple', 'red', 'orange', 'green', 'blue', 'indigo', 'violet']\n",
    "\n",
    "ks = [25, 50]\n",
    "\n",
    "methods = ['Baseline', 'CDI_Min_8_attr', 'CDI_Sum_8_attr', 'CDI_EucMin_8_attr', 'CDI_EucSum_8_attr']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3.4))\n",
    "q = 0\n",
    "c = 0\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision - Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2_c[(occ2_c['name'] == method) & (occ2_c['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_AbsBias_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_AbsBias_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles1, labels1 = ax[i].get_legend_handles_labels()\n",
    "\n",
    "\n",
    "fig.legend(handles1, labels1, loc='lower center', ncols=3, fontsize=9)\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2_c = pd.read_pickle('results/occ2-extra_concepts.pkl')\n",
    "\n",
    "print(occ2_c['name'].unique())\n",
    "print(occ2_c['k'].unique())\n",
    "\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple', 'red', 'orange', 'green', 'blue', 'indigo', 'violet']\n",
    "\n",
    "ks = [25, 50]\n",
    "\n",
    "methods = ['Baseline', 'CDI_Min_overconcept', 'CDI_Sum_overconcept', 'CDI_EucMin_overconcept', 'CDI_EucSum_overconcept']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3.4))\n",
    "q = 0\n",
    "c = 0\n",
    "for i, k in enumerate(ks):\n",
    "    ax[i].set_title(f'Precision - Subgroup @ {k}', weight='bold')\n",
    "    ax[i].set_ylim(0, .7)\n",
    "    ax[i].set_xlim(.8, 0)\n",
    "    ax[i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[i].set_xlabel('AbsBias in Gender', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2_c[(occ2_c['name'] == method) & (occ2_c['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[i].scatter(np.mean(data['Avg_AbsBias_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[i].plot(pareto_points['Avg_AbsBias_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles1, labels1 = ax[i].get_legend_handles_labels()\n",
    "\n",
    "\n",
    "fig.legend(handles1, labels1, loc='lower center', ncols=3, fontsize=9)\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occ2_male_queries = pd.read_pickle('results/occ2-3-31-gendered_queries_female.pkl')\n",
    "occ2_female_queries = pd.read_pickle('results/occ2-3-31-gendered_queries_female.pkl')\n",
    "\n",
    "print(occ2_male_queries)\n",
    "\n",
    "\n",
    "\n",
    "colors = ['black', '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2',\n",
    " '#7f7f7f', 'purple']\n",
    "\n",
    "ks = [25, 50]\n",
    "\n",
    "methods = occ2_male_queries['name'].unique()\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 6.))\n",
    "q = 0\n",
    "for i, k in enumerate(ks):\n",
    "    ax[q, i].set_title(f'Precision - Bias @ {k}', weight='bold')\n",
    "    ax[q, i].set_ylim(0, .7)\n",
    "    ax[q, i].set_xlim(.8, 0)\n",
    "    ax[q, i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[q, i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[q, i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[j]\n",
    "        data = occ2_male_queries[(occ2_male_queries['name'] == method) & (occ2_male_queries['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[q, i].scatter(np.mean(data['Avg_Bias_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[q, i].plot(pareto_points['Avg_Bias_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles1, labels1 = ax[q, i].get_legend_handles_labels()\n",
    "\n",
    "methods = ['Baseline', 'CDI_Sum_3_attr', 'CDI_Sum_6_attr', 'CDI_Sum_8_attr']\n",
    "q = 1\n",
    "for i, k in enumerate(ks):\n",
    "    ax[q, i].set_title(f'Precision - Bias @ {k}', weight='bold')\n",
    "    ax[q, i].set_ylim(0, .7)\n",
    "    ax[q, i].set_xlim(.8, 0)\n",
    "    ax[q, i].grid(True)\n",
    "    if i == 0:\n",
    "        ax[q, i].set_ylabel('Precision', weight='bold', fontsize=12)\n",
    "    ax[q, i].set_xlabel('Subgroup Bias', weight='bold')    \n",
    "    for j, method in enumerate(methods):\n",
    "        c = colors[3 + j]\n",
    "        data = occ2_female_queries[(occ2_female_queries['name'] == method) & (occ2_female_queries['k'] == k)]\n",
    "        if method in ['Baseline', 'DebiasClip']:\n",
    "            ax[q, i].scatter(np.mean(data['Avg_Bias_gender']), np.mean(data['Avg_Precision']), label=method, s=15, c='black')\n",
    "        else:\n",
    "            avg_c = avg_cats(data, \"tol\")\n",
    "            #pareto_front = is_pareto_efficient_simple(avg_c, metric, 'Avg_Precision')\n",
    "            pareto_points = avg_c #avg_c.iloc[pareto_front]\n",
    "            ax[q, i].plot(pareto_points['Avg_Bias_gender'], pareto_points['Avg_Precision'], label=method, c=c, linewidth=2.1)\n",
    "\n",
    "    handles2, labels2 = ax[q, i].get_legend_handles_labels()\n",
    "\n",
    "fig.legend(handles1, labels1, loc='lower center', ncols=3, fontsize=11)\n",
    "fig.tight_layout(rect=[0, 0, 1.2, 1.2])\n",
    "fig.subplots_adjust(bottom=0.25)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.covariance import empirical_covariance\n",
    "\n",
    "data = np.asarray([[0, 0], [1, 1], [0, 1], [1, 0]])\n",
    "data_miscalibrated = np.asarray([[.3, 0], [.7, 1], [.3, 1], [.7, 0]])\n",
    "data_covariation_error = np.asarray([[0, 0], [1, 1], [0, 1], [.6, .4]])\n",
    "\n",
    "plt.figure(figsize=(2.4, 2.4))\n",
    "plt.scatter(data[:, 0], data[:, 1])\n",
    "plt.xlabel('Attribute 1', weight='bold')\n",
    "plt.ylabel('Attribute 2', weight='bold')\n",
    "plt.title('Concepts', weight='bold')\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2.4, 2.4))\n",
    "plt.scatter(data_miscalibrated[:, 0], data_miscalibrated[:, 1])\n",
    "plt.xlabel('Attribute 1', weight='bold')\n",
    "plt.ylabel('Attribute 2', weight='bold')\n",
    "plt.title('Miscalibrated', weight='bold')\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(2.4, 2.4))\n",
    "plt.scatter(data_covariation_error[:, 0], data_covariation_error[:, 1])\n",
    "plt.xlabel('Attribute 1', weight='bold')\n",
    "plt.ylabel('Attribute 2', weight='bold')\n",
    "plt.title('Covariation', weight='bold')\n",
    "plt.xlim(-.05, 1.05)\n",
    "plt.ylim(-.05, 1.05)\n",
    "plt.show()\n",
    "\n",
    "print(cdist(data, data, 'euclidean'))\n",
    "print(cdist(data_miscalibrated, data_miscalibrated, 'euclidean'))\n",
    "print(cdist(data_covariation_error, data_covariation_error, 'euclidean'))\n",
    "print(empirical_covariance(data_covariation_error))\n",
    "print(cdist(data, data, 'mahalanobis'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
