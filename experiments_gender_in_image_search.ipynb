{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "import bisect \n",
    "from scipy.spatial import ConvexHull\n",
    "import gc\n",
    "import debias_clip as dclip\n",
    "import copy\n",
    "import sklearn.feature_selection as fs\n",
    "from image_database import *\n",
    "#import cvxpy as cp\n",
    "image_folder_prefix = 'datasets/gender_in_image_search/google/'\n",
    "\n",
    "data = pd.read_csv('datasets/gender_in_image_search/gender_labelled_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing\n",
    "\n",
    "catagories = data['search_term'].unique()\n",
    "data['image_relative_path'] = data['image_url'].str.replace(\"http://homes.cs.washington.edu/~mjskay/aws-images/google/\", image_folder_prefix)\n",
    "\n",
    "print(len(catagories))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "features = process_images(model, preprocess, data['image_relative_path'], batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_d = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_debias, preprocess_debias = dclip.load(\"ViT-B/16-gender\", device_d)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "features_debias = process_images(model_debias, preprocess_debias, data['image_relative_path'], batch_size=batch_size, device=device_d)\n",
    "\n",
    "device_d = 'cpu'\n",
    "model_debias, preprocess_debias = dclip.load(\"ViT-B/16-gender\", device_d)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "image_database.sensitive_attributes([(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of a young person\", \"A picture of an old person\")])\n",
    "\n",
    "#print(image_database.search(\"This is a picture of a engineer.\"))\n",
    "print(image_database.distinct_retrival(\"This is a picture of a pilot.\", method='feature_distances', k=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "image_database.sensitive_attributes([(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")]) #\n",
    "image_database.define_pbm_classes([\"unknown gender\", \"man\", \"woman\"])\n",
    "debias_database = ImageDatabase(features_debias, data, model_debias, preprocess_debias, device_d)\n",
    "\n",
    "baseline_metrics = {'name': 'Baseline'}\n",
    "random_from_similar_set_metrics = {'name': 'RandomSS'}\n",
    "divimage_max_sum_metrics = {'name': 'DivImageMSum'}\n",
    "divimage_max_min_metrics = {'name': 'DivImageMMin'}\n",
    "#diviamge_clustering_metrics = {'name': 'DivImageC'}\n",
    "#divimage_qp_metrics = {'name': 'DivImageQP'}\n",
    "random_from_similar_set_metrics_larger_tol = {'name': 'RandomSS'}\n",
    "divimage_max_sum_metrics_larger_tol = {'name': 'DivImageMSum'}\n",
    "divimage_max_min_metrics_larger_tol = {'name': 'DivImageMMin'}\n",
    "pbm_metrics = {'name': 'PBM'}\n",
    "pbm_intersectional_metrics = {'name': 'PBM_Intersectional'}\n",
    "debias_clip_metrics = {'name': 'DebiasClip'}\n",
    "true_labels = {'name': 'TrueConceptLabels'}\n",
    "true_labels_larger_tol = {'name': 'TrueConceptLabels'}\n",
    "\n",
    "\n",
    "indistinguisable_values = [[cat] for cat in catagories]\n",
    "true_rates = [[data[data['search_term'] == cat].iloc[0].search_p_women for cat in catagories]]\n",
    "totals_by_cat = {cat: len(data[data['search_term'] == cat]) for cat in catagories}\n",
    "image_database.define_coordinate_mapping(['image_gender'], [['man']], [['woman']])\n",
    "\n",
    "run_analysis(lambda x: image_database.search(x, 50), 50, None, baseline_metrics, catagories, 'search_term', indistinguisable_values, ['image_gender'], [['woman']], [['man']], true_rates, totals_by_cat)\n",
    "run_analysis(lambda x: image_database.distinct_retrival(x, 50, tol=.03, method='max_sum'), 50, .03, divimage_max_sum_metrics, catagories, 'search_term', indistinguisable_values, ['image_gender'], [['woman']], [['man']], true_rates, totals_by_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(baseline_metrics.keys())\n",
    "#print(baseline_metrics['bias'])\n",
    "divimage_max_sum_metrics\n",
    "\n",
    "plt.scatter(baseline_metrics['bias'], baseline_metrics['precision'], alpha=.8)\n",
    "plt.scatter(divimage_max_sum_metrics['bias'], divimage_max_sum_metrics['precision'], alpha=.8)\n",
    "plt.title(\"Bias vs Precision on GIIS\", weight='bold')\n",
    "plt.xlabel(\"Gender Bias\", weight='bold', fontsize=12)\n",
    "plt.ylabel(\"Precision\", weight='bold', fontsize=12)\n",
    "plt.legend([\"Baseline\", \"CDI-MaxSum, tol = .03\"], loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "totals_by_cat = {cat: len(data[data['search_term'] == cat]) for cat in catagories}\n",
    "image_database.define_coordinate_mapping(['image_gender'], [['man']], [['woman']])\n",
    "indistinguisable_values = [[cat] for cat in catagories]\n",
    "true_rates = [[data[data['search_term'] == cat].iloc[0].search_p_women for cat in catagories]]\n",
    "totals_by_cat = {cat: len(data[data['search_term'] == cat]) for cat in catagories}\n",
    "\n",
    "image_database.add_clipclip_ordering(\"gender\", np.load('datasets/MI_orders/gender.npy'))\n",
    "image_database.add_clipclip_ordering(\"skintone\", np.load('datasets/MI_orders/skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/gender_skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"three_attr\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "\n",
    "\n",
    "\"\"\"method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='random'), 'CDI_Random', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='true_labels'), 'CDI_TrueConcept', []),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_gender', [(\"pbm_classes\", [\"unknown gender\", \"man\", \"woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_intersectional', [(\"pbm_classes\", [\"unknown gender and skin-tone\", \"light-skinned man\", \"light-skinned woman\", \"dark-skinned man\", \"dark-skinned woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_skintone', [(\"pbm_classes\", [\"unknown skin-tone\", \"light-skinned person\", \"dark-skinned person\"])]),\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\"\"\"\n",
    "\n",
    "\"\"\"method_name_specification_list = [\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_gender', [(\"pbm_classes\", [\"unknown gender\", \"man\", \"woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_intersectional', [(\"pbm_classes\", [\"unknown gender and skin-tone\", \"light-skinned man\", \"light-skinned woman\", \"dark-skinned man\", \"dark-skinned woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_skintone', [(\"pbm_classes\", [\"unknown skin-tone\", \"light-skinned person\", \"dark-skinned person\"])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='feature_distances'), 'CDI_Features', [])\n",
    "]\"\"\"\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender\", n, k), 'CLIP_gender', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"skintone\", n, k), 'CLIP_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"three_attr\", n, k), 'CLIP_three_attributes', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='euc_max_sum'), 'CDI_EucSum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='euc_max_min'), 'CDI_EucMin_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])])\n",
    "]\n",
    "\n",
    "ks = [10, 25, 50, 100]\n",
    "\n",
    "number_of_tol_steps = 16\n",
    "number_of_eps_steps = 11\n",
    "random_iters = 4\n",
    "number_of_clip_clip_steps = 24\n",
    "\n",
    "result_dicts = []\n",
    "\n",
    "for method, name, spec in method_name_specification_list:\n",
    "    print(f\"Starting analysis for method: {name}...\")\n",
    "    for s, val in spec:\n",
    "        if s == \"sensitive_attributes\":\n",
    "            image_database.sensitive_attributes(val)\n",
    "        if s == \"pbm_classes\":\n",
    "            image_database.define_pbm_classes(val)\n",
    "    for k in tqdm(ks):\n",
    "        result_dict = {'name': name}\n",
    "\n",
    "        if name in ['Baseline', \"DebiasClip\"]:\n",
    "            steps = 1\n",
    "        else:\n",
    "            steps = number_of_tol_steps\n",
    "\n",
    "        if name[0:3] == 'PBM':\n",
    "            for e in reversed(range(0, number_of_eps_steps)):\n",
    "                eps = e / (number_of_eps_steps - 1)\n",
    "                retrieval_function = method(k, eps)\n",
    "                new_dict = result_dict.copy()\n",
    "                random_results = []\n",
    "                for i in range(random_iters):\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis(retrieval_function, k, eps, new_dict, catagories, 'search_term', indistinguisable_values,  ['image_gender'], [['woman']], [['man']], true_rates, totals_by_cat)\n",
    "                    random_results.append(new_dict)\n",
    "                \n",
    "                add_dict = result_dict.copy()\n",
    "                for key in random_results[0].keys():\n",
    "                    if key == 'name':\n",
    "                        continue\n",
    "                    add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                result_dicts.append(add_dict)\n",
    "        \n",
    "        elif name[0:4] == 'CLIP':\n",
    "            for e in range(0, number_of_clip_clip_steps):\n",
    "                n = e * 20\n",
    "                retrieval_function = method(k, n)\n",
    "                new_dict = result_dict.copy()\n",
    "                run_analysis(retrieval_function, k, n, new_dict, catagories, 'search_term', indistinguisable_values, ['image_gender'],  [['woman']], [['man']], true_rates, totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "\n",
    "        else:\n",
    "            for t in range(0, steps):\n",
    "                if steps == 1:\n",
    "                    tol = None\n",
    "                else:\n",
    "                    tol = t / 200\n",
    "                retrieval_function = method(k, tol)\n",
    "                new_dict = result_dict.copy()\n",
    "                if name == \"CDI_Random\":\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis(retrieval_function, k, tol, new_dict, catagories, 'search_term', indistinguisable_values,  ['image_gender'], [['woman']], [['man']], true_rates, totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    new_dict = result_dict.copy()\n",
    "\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                else:\n",
    "                    run_analysis(retrieval_function, k, tol, new_dict, catagories, 'search_term', indistinguisable_values, ['image_gender'], [['woman']], [['man']], true_rates, totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis(result_dicts, ['gender'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_pickle(\"results/giis-3-24-CLIP-euc.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_pickle(\"results/giis-3-21.pkl\")\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_names = ['Baseline', 'DebiasClip', \"CDI_Sum_gender\"]\n",
    "method_names = df2['name'].unique()\n",
    "\n",
    "for k in [10, 25, 50, 100]:\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_AbsBias_gender', 'Avg_Precision', reverse_x=True)\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_Bias_gender', 'Avg_Precision', reverse_x=False)\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_Skew_gender', 'Avg_Precision', reverse_x=False)\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_AbsBias_gender', 'Avg_Recall', reverse_x=True)\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_Bias_gender', 'Avg_Recall', reverse_x=False)\n",
    "    plot_across_tol(df2, 25, method_names, 'Avg_AbsBias_for_Accurate_gender', 'Avg_Precision', reverse_x=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
