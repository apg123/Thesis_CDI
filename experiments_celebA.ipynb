{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from image_database import *\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "import bisect \n",
    "from scipy.spatial import ConvexHull\n",
    "import gc\n",
    "import debias_clip as dclip\n",
    "#import cvxpy as cp\n",
    "image_folder_prefix = 'datasets/celeba/img_align_celeba/'\n",
    "\n",
    "data = pd.read_csv('datasets/celeba/alg_testing.csv') #datasets\\occuptations_2\\occupations_labels.csv\n",
    "data = data.astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['Pale_Skin'] == '1'].head())\n",
    "\n",
    "for image_loc in data[data['Pale_Skin'] == '-1']['image_id']:\n",
    "    image = Image.open(image_folder_prefix + image_loc)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('datasets/celeba/features.npy')[20000:35000]\n",
    "\n",
    "features_debias = np.load('datasets/celeba/features_debias.npy')[20000:35000]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pretrained embedings\n",
      " best_ndkl_oai-clip-vit-b-16_neptune_run_OXVLB-317_model_e4_step_5334_embeddings.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 4.73k/4.73k [00:00<00:00, 1.23MiB/s]\n"
     ]
    }
   ],
   "source": [
    "device_d = 'cpu'\n",
    "model_debias, preprocess_debias = dclip.load(\"ViT-B/16-gender\", device_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        -1\n",
      "1        -1\n",
      "2        -1\n",
      "3        -1\n",
      "4         1\n",
      "         ..\n",
      "14995    -1\n",
      "14996    -1\n",
      "14997    -1\n",
      "14998    -1\n",
      "14999    -1\n",
      "Name: 5_o_Clock_Shadow, Length: 15000, dtype: string\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>020001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>020002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>020003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>020004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>020005.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0    image_id 5_o_Clock_Shadow Arched_Eyebrows Attractive  \\\n",
       "0      20000  020001.jpg               -1               1          1   \n",
       "1      20001  020002.jpg               -1              -1         -1   \n",
       "2      20002  020003.jpg               -1              -1          1   \n",
       "3      20003  020004.jpg               -1              -1         -1   \n",
       "4      20004  020005.jpg                1              -1         -1   \n",
       "\n",
       "  Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose  ... Sideburns Smiling  \\\n",
       "0               1   -1    -1       -1        1  ...        -1      -1   \n",
       "1              -1    1    -1       -1       -1  ...        -1      -1   \n",
       "2              -1   -1     1       -1       -1  ...        -1      -1   \n",
       "3              -1   -1     1       -1       -1  ...        -1      -1   \n",
       "4               1   -1    -1       -1       -1  ...        -1      -1   \n",
       "\n",
       "  Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick  \\\n",
       "0            -1        -1                1          -1                1   \n",
       "1            -1        -1               -1          -1               -1   \n",
       "2             1        -1                1          -1               -1   \n",
       "3            -1         1               -1          -1               -1   \n",
       "4            -1        -1               -1          -1               -1   \n",
       "\n",
       "  Wearing_Necklace Wearing_Necktie Young  \n",
       "0                1              -1     1  \n",
       "1               -1               1    -1  \n",
       "2               -1              -1     1  \n",
       "3               -1              -1     1  \n",
       "4               -1               1     1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['5_o_Clock_Shadow'])\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Random...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [1:18:30<00:00, 1177.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     method        name    tol      k  Avg_Precision  \\\n",
      "0     CDI_Random (tol: 0.0)  CDI_Random  0.000   10.0       0.800000   \n",
      "1   CDI_Random (tol: 0.005)  CDI_Random  0.005   10.0       0.753571   \n",
      "2    CDI_Random (tol: 0.01)  CDI_Random  0.010   10.0       0.778571   \n",
      "3   CDI_Random (tol: 0.015)  CDI_Random  0.015   10.0       0.757143   \n",
      "4    CDI_Random (tol: 0.02)  CDI_Random  0.020   10.0       0.703571   \n",
      "..                      ...         ...    ...    ...            ...   \n",
      "59  CDI_Random (tol: 0.055)  CDI_Random  0.055  100.0       0.545357   \n",
      "60   CDI_Random (tol: 0.06)  CDI_Random  0.060  100.0       0.544643   \n",
      "61  CDI_Random (tol: 0.065)  CDI_Random  0.065  100.0       0.536786   \n",
      "62   CDI_Random (tol: 0.07)  CDI_Random  0.070  100.0       0.533571   \n",
      "63  CDI_Random (tol: 0.075)  CDI_Random  0.075  100.0       0.538929   \n",
      "\n",
      "    Avg_Recall  Avg_PutI  Avg_AbsBias_Pale_Skin  Avg_Bias_Pale_Skin  \\\n",
      "0     0.006960  0.800000               0.942857           -0.942857   \n",
      "1     0.006548  0.753571               0.900000           -0.900000   \n",
      "2     0.006726  0.778571               0.864286           -0.864286   \n",
      "3     0.006302  0.757143               0.800000           -0.800000   \n",
      "4     0.005988  0.703571               0.878571           -0.878571   \n",
      "..         ...       ...                    ...                 ...   \n",
      "59    0.036699  0.545357               0.907857           -0.907857   \n",
      "60    0.036543  0.544643               0.900714           -0.900714   \n",
      "61    0.035981  0.536786               0.908571           -0.908571   \n",
      "62    0.035438  0.533571               0.901429           -0.901429   \n",
      "63    0.036091  0.538929               0.902857           -0.902857   \n",
      "\n",
      "    Avg_AbsBias_for_Accurate_Pale_Skin  Avg_AbsBias_Male  Avg_Bias_Male  \\\n",
      "0                             0.896825          0.542857      -0.028571   \n",
      "1                             0.870238          0.471429       0.042857   \n",
      "2                             0.858645          0.485714       0.142857   \n",
      "3                             0.766015          0.500000       0.100000   \n",
      "4                             0.862897          0.478571       0.307143   \n",
      "..                                 ...               ...            ...   \n",
      "59                            0.918508          0.303571       0.096429   \n",
      "60                            0.896512          0.292857       0.115714   \n",
      "61                            0.916275          0.302857       0.140000   \n",
      "62                            0.918493          0.307857       0.136429   \n",
      "63                            0.895313          0.320000       0.130000   \n",
      "\n",
      "    Avg_AbsBias_for_Accurate_Male  Avg_AbsBias_Young  Avg_Bias_Young  \\\n",
      "0                        0.588209           0.742857        0.514286   \n",
      "1                        0.510034           0.750000        0.521429   \n",
      "2                        0.576871           0.771429        0.514286   \n",
      "3                        0.596344           0.742857        0.500000   \n",
      "4                        0.591298           0.750000        0.478571   \n",
      "..                            ...                ...             ...   \n",
      "59                       0.474783           0.568571        0.500000   \n",
      "60                       0.438697           0.561429        0.495714   \n",
      "61                       0.435416           0.578571        0.528571   \n",
      "62                       0.436057           0.557857        0.516429   \n",
      "63                       0.438703           0.553571        0.485000   \n",
      "\n",
      "    Avg_AbsBias_for_Accurate_Young  Avg_Max_MC_Bias  Max_AbsBias  \n",
      "0                         0.765079         0.671429     0.942857  \n",
      "1                         0.809921         0.621429     0.900000  \n",
      "2                         0.791582         0.632143     0.864286  \n",
      "3                         0.737358         0.589286     0.800000  \n",
      "4                         0.770833         0.625000     0.878571  \n",
      "..                             ...              ...          ...  \n",
      "59                        0.611979         0.515000     0.907857  \n",
      "60                        0.617830         0.503214     0.900714  \n",
      "61                        0.606501         0.502857     0.908571  \n",
      "62                        0.620820         0.502500     0.901429  \n",
      "63                        0.622204         0.508214     0.902857  \n",
      "\n",
      "[64 rows x 18 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "catagories = ['attractive person', 'blurry photo of a person', 'person with brown hair', 'person wearing eyeglasses', 'person with gray hair', 'smiling person', 'person in a hat']\n",
    "catagory_column = ['Attractive', 'Blurry', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Smiling', 'Wearing_Hat']\n",
    "\n",
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "indistinguisable_values = [[\"1\"] for cat in catagory_column]\n",
    "totals_by_cat = {cat: len(data[data[catagory_column[i]] == \"1\"]) for i, cat in enumerate(catagories)}\n",
    "image_database.define_coordinate_mapping(['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']])\n",
    "\n",
    "debias_database = ImageDatabase(features_debias, data, model_debias, preprocess_debias, device_d)\n",
    "\n",
    "image_database.add_clipclip_ordering(\"gender\", np.load('datasets/MI_orders/gender.npy'))\n",
    "image_database.add_clipclip_ordering(\"skintone\", np.load('datasets/MI_orders/skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"age\", np.load('datasets/MI_orders/age.npy'))\n",
    "image_database.add_clipclip_ordering(\"gender_skintone\", np.load('datasets/MI_orders/gender_skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "image_database.add_clipclip_ordering(\"additional_concepts\", np.load('datasets/MI_orders/additional_concepts.npy'))\n",
    "\n",
    "\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_age', [(\"sensitive_attributes\", [(\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_age', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='feature_distances'), 'CDI_Features', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='true_labels'), 'CDI_TrueConcept', []),\n",
    "    \n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_gender', [(\"pbm_classes\", [\"unknown gender\", \"man\", \"woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_intersectional', [(\"pbm_classes\", [\"unknown gender and skin-tone\", \"light-skinned man\", \"light-skinned woman\", \"dark-skinned man\", \"dark-skinned woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_skintone', [(\"pbm_classes\", [\"unknown skin-tone\", \"light-skinned person\", \"dark-skinned person\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_three_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, and gender\", \"\"))]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_four_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"American\", \"non-American\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, nationality, and gender\", \"\"))]),\n",
    "    \n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender\", n, k), 'CLIP_gender', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"skintone\", n, k), 'CLIP_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"age\", n, k), 'CLIP_age', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender_skintone\", n, k), 'CLIP_gender_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"additional_concepts\", n, k), 'CLIP_add_concept', []),\n",
    "\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='random'), 'CDI_Random', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ks = [10, 25, 50, 100]  # [10, 25, 50, 100] \n",
    "\n",
    "number_of_tol_steps = 16 # 16\n",
    "number_of_eps_steps = 11 # 11\n",
    "number_of_clip_clip_steps = 24 #24\n",
    "random_iters = 4 #4\n",
    "\n",
    "result_dicts = []\n",
    "\n",
    "for method, name, spec in method_name_specification_list:\n",
    "    print(f\"Starting analysis for method: {name}...\")\n",
    "    for s, val in spec:\n",
    "        if s == \"sensitive_attributes\":\n",
    "            image_database.sensitive_attributes(val)\n",
    "        if s == \"pbm_classes\":\n",
    "            image_database.define_pbm_classes(val)\n",
    "    for k in tqdm(ks):\n",
    "        result_dict = {'name': name}\n",
    "\n",
    "        if name in ['Baseline', \"DebiasClip\"]:\n",
    "            steps = 1\n",
    "        else:\n",
    "            steps = number_of_tol_steps\n",
    "\n",
    "        if name[0:3] == 'PBM':\n",
    "            for e in reversed(range(0, number_of_eps_steps)):\n",
    "                eps = e / (number_of_eps_steps - 1)\n",
    "                retrieval_function = method(k, eps)\n",
    "                new_dict = result_dict.copy()\n",
    "                random_results = []\n",
    "                for i in range(random_iters):\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis_celeba(retrieval_function, k, eps, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    random_results.append(new_dict)\n",
    "                \n",
    "                add_dict = result_dict.copy()\n",
    "                for key in random_results[0].keys():\n",
    "                    if key == 'name':\n",
    "                        continue\n",
    "                    add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                result_dicts.append(add_dict)\n",
    "\n",
    "        elif name[0:4] == 'CLIP':\n",
    "            for e in range(0, number_of_clip_clip_steps):\n",
    "                n = e * 20\n",
    "                retrieval_function = method(k, n)\n",
    "                new_dict = result_dict.copy()\n",
    "                run_analysis_celeba(retrieval_function, k, n, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "        else:\n",
    "            for t in range(0, steps):\n",
    "                if steps == 1:\n",
    "                    tol = None\n",
    "                else:\n",
    "                    tol = t / 200\n",
    "                retrieval_function = method(k, tol)\n",
    "                new_dict = result_dict.copy()\n",
    "                if name == \"CDI_Random\":\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    new_dict = result_dict.copy()\n",
    "\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                else:\n",
    "                    run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis_celeba(result_dicts, ['Pale_Skin', 'Male', 'Young'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_pickle(\"results/celeba-random.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"results/celeba-3-24.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:05<00:00, 166.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:48<00:00, 87.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:12<00:00, 33.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:26<00:00,  6.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  4.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:58<00:00, 89.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:28<00:00, 97.15s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:47<00:00, 26.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:22<00:00,  5.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:02<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:14<00:00, 93.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:07<00:00, 91.95s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:28<00:00, 52.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:05<00:00, 16.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:10<00:00, 92.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [11:41<00:00, 175.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:11<00:00, 62.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:16<00:00, 19.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:55<00:00, 73.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [06:36<00:00, 99.17s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:44<00:00, 56.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:15<00:00, 18.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.79s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a white person\", \"A picture of a non-white person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a white person\", \"A picture of a non-white person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_three_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"white\", \"non-white\"], [\"old\", \"young\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, and gender\", \"\"))]),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\n",
    "np.random.seed(123)\n",
    "\n",
    "catagories = ['attractive person', 'blurry photo of a person', 'person with brown hair', 'person wearing eyeglasses', 'person with gray hair', 'smiling person', 'person in a hat']\n",
    "catagory_column = ['Attractive', 'Blurry', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Smiling', 'Wearing_Hat']\n",
    "\n",
    "features = np.load('datasets/celeba/features.npy')\n",
    "features_debias = np.load('datasets/celeba/features_debias.npy')\n",
    "\n",
    "data = pd.read_csv('datasets/celeba/list_attr_celeba.csv')\n",
    "data = data.astype('string')\n",
    "\n",
    "start_idx = 20000\n",
    "step_idx = 15000\n",
    "\n",
    "result_dicts = []\n",
    "for runs in range(5):\n",
    "    lb = start_idx + runs * step_idx\n",
    "    ub = start_idx + (runs + 1) * step_idx\n",
    "    f_random = features[lb:ub]\n",
    "    d_random = data.iloc[lb:ub]\n",
    "    fd_random = features_debias[lb:ub]\n",
    "    image_database = ImageDatabase(f_random, d_random, model, preprocess, device)\n",
    "    indistinguisable_values = [[\"1\"] for cat in catagory_column]\n",
    "    totals_by_cat = {cat: len(data[data[catagory_column[i]] == \"1\"]) for i, cat in enumerate(catagories)}\n",
    "    image_database.define_coordinate_mapping(['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']])\n",
    "    \n",
    "    debias_database = ImageDatabase(fd_random, d_random, model_debias, preprocess_debias, device_d)\n",
    "    image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "\n",
    "    ks = [10, 25, 50, 100] # [10, 25, 50, 100] \n",
    "\n",
    "    number_of_tol_steps = 16 # 16\n",
    "    number_of_eps_steps = 11 # 11\n",
    "    number_of_clip_clip_steps = 24 #24\n",
    "    random_iters = 4 #4\n",
    "\n",
    "    for method, name, spec in method_name_specification_list:\n",
    "        print(f\"Starting analysis for method: {name}...\")\n",
    "        for s, val in spec:\n",
    "            if s == \"sensitive_attributes\":\n",
    "                image_database.sensitive_attributes(val)\n",
    "            if s == \"pbm_classes\":\n",
    "                image_database.define_pbm_classes(val)\n",
    "        for k in tqdm(ks):\n",
    "            result_dict = {'name': name}\n",
    "\n",
    "            if name in ['Baseline', \"DebiasClip\"]:\n",
    "                steps = 1\n",
    "            else:\n",
    "                steps = number_of_tol_steps\n",
    "\n",
    "            if name[0:3] == 'PBM':\n",
    "                for e in reversed(range(0, number_of_eps_steps)):\n",
    "                    eps = e / (number_of_eps_steps - 1)\n",
    "                    retrieval_function = method(k, eps)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis_celeba(retrieval_function, k, eps, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    \n",
    "                    add_dict = result_dict.copy()\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                    result_dicts.append(add_dict)\n",
    "\n",
    "            elif name[0:4] == 'CLIP':\n",
    "                for e in range(0, number_of_clip_clip_steps):\n",
    "                    n = e * 20\n",
    "                    retrieval_function = method(k, n)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis_celeba(retrieval_function, k, n, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    result_dicts.append(new_dict)\n",
    "            else:\n",
    "                for t in range(0, steps):\n",
    "                    if steps == 1:\n",
    "                        tol = None\n",
    "                    else:\n",
    "                        tol = t / 200\n",
    "                    retrieval_function = method(k, tol)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    if name == \"CDI_Random\":\n",
    "                        random_results = []\n",
    "                        for i in range(random_iters):\n",
    "                            new_dict = result_dict.copy()\n",
    "                            run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                            random_results.append(new_dict)\n",
    "                        new_dict = result_dict.copy()\n",
    "\n",
    "                        for key in random_results[0].keys():\n",
    "                            if key == 'name':\n",
    "                                continue\n",
    "                            new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                    else:\n",
    "                        run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis_celeba(result_dicts, ['Pale_Skin', 'Male', 'Young'])\n",
    "\n",
    "df.to_pickle(\"results/celeba-validation-white-nonwhite.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
