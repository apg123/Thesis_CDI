{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from image_database import *\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "import bisect \n",
    "from scipy.spatial import ConvexHull\n",
    "import gc\n",
    "import debias_clip as dclip\n",
    "#import cvxpy as cp\n",
    "image_folder_prefix = 'datasets/celeba/img_align_celeba/'\n",
    "\n",
    "data = pd.read_csv('datasets/celeba/alg_testing.csv') #datasets\\occuptations_2\\occupations_labels.csv\n",
    "data = data.astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('datasets/celeba/features.npy')[20000:35000]\n",
    "\n",
    "features_debias = np.load('datasets/celeba/features_debias.npy')[20000:35000]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing pretrained embedings\n",
      " best_ndkl_oai-clip-vit-b-16_neptune_run_OXVLB-317_model_e4_step_5334_embeddings.pt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4.73k/4.73k [00:00<?, ?iB/s]\n"
     ]
    }
   ],
   "source": [
    "device_d = 'cpu'\n",
    "model_debias, preprocess_debias = dclip.load(\"ViT-B/16-gender\", device_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        -1\n",
      "1        -1\n",
      "2        -1\n",
      "3        -1\n",
      "4         1\n",
      "         ..\n",
      "14995    -1\n",
      "14996    -1\n",
      "14997    -1\n",
      "14998    -1\n",
      "14999    -1\n",
      "Name: 5_o_Clock_Shadow, Length: 15000, dtype: string\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>5_o_Clock_Shadow</th>\n",
       "      <th>Arched_Eyebrows</th>\n",
       "      <th>Attractive</th>\n",
       "      <th>Bags_Under_Eyes</th>\n",
       "      <th>Bald</th>\n",
       "      <th>Bangs</th>\n",
       "      <th>Big_Lips</th>\n",
       "      <th>Big_Nose</th>\n",
       "      <th>...</th>\n",
       "      <th>Sideburns</th>\n",
       "      <th>Smiling</th>\n",
       "      <th>Straight_Hair</th>\n",
       "      <th>Wavy_Hair</th>\n",
       "      <th>Wearing_Earrings</th>\n",
       "      <th>Wearing_Hat</th>\n",
       "      <th>Wearing_Lipstick</th>\n",
       "      <th>Wearing_Necklace</th>\n",
       "      <th>Wearing_Necktie</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>020001.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001</td>\n",
       "      <td>020002.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20002</td>\n",
       "      <td>020003.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20003</td>\n",
       "      <td>020004.jpg</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004</td>\n",
       "      <td>020005.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0    image_id 5_o_Clock_Shadow Arched_Eyebrows Attractive  \\\n",
       "0      20000  020001.jpg               -1               1          1   \n",
       "1      20001  020002.jpg               -1              -1         -1   \n",
       "2      20002  020003.jpg               -1              -1          1   \n",
       "3      20003  020004.jpg               -1              -1         -1   \n",
       "4      20004  020005.jpg                1              -1         -1   \n",
       "\n",
       "  Bags_Under_Eyes Bald Bangs Big_Lips Big_Nose  ... Sideburns Smiling  \\\n",
       "0               1   -1    -1       -1        1  ...        -1      -1   \n",
       "1              -1    1    -1       -1       -1  ...        -1      -1   \n",
       "2              -1   -1     1       -1       -1  ...        -1      -1   \n",
       "3              -1   -1     1       -1       -1  ...        -1      -1   \n",
       "4               1   -1    -1       -1       -1  ...        -1      -1   \n",
       "\n",
       "  Straight_Hair Wavy_Hair Wearing_Earrings Wearing_Hat Wearing_Lipstick  \\\n",
       "0            -1        -1                1          -1                1   \n",
       "1            -1        -1               -1          -1               -1   \n",
       "2             1        -1                1          -1               -1   \n",
       "3            -1         1               -1          -1               -1   \n",
       "4            -1        -1               -1          -1               -1   \n",
       "\n",
       "  Wearing_Necklace Wearing_Necktie Young  \n",
       "0                1              -1     1  \n",
       "1               -1               1    -1  \n",
       "2               -1              -1     1  \n",
       "3               -1              -1     1  \n",
       "4               -1               1     1  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['5_o_Clock_Shadow'])\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: Baseline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:01<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_gender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [10:16<00:00, 154.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_gender_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [22:34<00:00, 338.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:09<00:00, 77.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_age...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:34<00:00, 38.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:47<00:00, 71.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Sum_4_attr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:33<00:00, 53.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_gender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:11<00:00, 47.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_gender_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:05<00:00, 61.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:07<00:00, 61.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_age...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [16:54<00:00, 253.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [13:19<00:00, 199.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Min_4_attr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [18:00<00:00, 270.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_Features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [32:11<00:00, 482.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CDI_TrueConcept...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [31:11<00:00, 467.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_gender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:30<00:00, 52.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:54<00:00, 58.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [03:34<00:00, 53.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_three_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:38<00:00, 69.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: PBM_four_attributes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:36<00:00, 84.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_gender...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:19<00:00, 19.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:27<00:00, 21.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_age...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:18<00:00, 19.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_gender_skintone...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:26<00:00, 21.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_intersectional...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:20<00:00, 20.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: CLIP_add_concept...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:24<00:00, 21.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting analysis for method: DebiasClip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:15<00:00,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           method              name    tol      k  \\\n",
      "0                        Baseline          Baseline    NaN   10.0   \n",
      "1                        Baseline          Baseline    NaN   25.0   \n",
      "2                        Baseline          Baseline    NaN   50.0   \n",
      "3                        Baseline          Baseline    NaN  100.0   \n",
      "4       CDI_Sum_gender (tol: 0.0)    CDI_Sum_gender    0.0   10.0   \n",
      "...                           ...               ...    ...    ...   \n",
      "1695  CLIP_add_concept (tol: 460)  CLIP_add_concept  460.0  100.0   \n",
      "1696                   DebiasClip        DebiasClip    NaN   10.0   \n",
      "1697                   DebiasClip        DebiasClip    NaN   25.0   \n",
      "1698                   DebiasClip        DebiasClip    NaN   50.0   \n",
      "1699                   DebiasClip        DebiasClip    NaN  100.0   \n",
      "\n",
      "      Avg_Precision  Avg_Recall  Avg_PutI  Avg_AbsBias_Pale_Skin  \\\n",
      "0          0.800000    0.006960  0.800000               0.942857   \n",
      "1          0.782857    0.017001  0.782857               0.908571   \n",
      "2          0.771429    0.032874  0.771429               0.880000   \n",
      "3          0.758571    0.064078  0.758571               0.885714   \n",
      "4          0.800000    0.006960  0.800000               0.942857   \n",
      "...             ...         ...       ...                    ...   \n",
      "1695       0.261429    0.018650  0.261429               0.914286   \n",
      "1696       0.685714    0.006127  0.685714               0.942857   \n",
      "1697       0.714286    0.015298  0.714286               0.942857   \n",
      "1698       0.708571    0.029098  0.708571               0.931429   \n",
      "1699       0.702857    0.056559  0.702857               0.925714   \n",
      "\n",
      "      Avg_Bias_Pale_Skin  Avg_AbsBias_for_Accurate_Pale_Skin  \\\n",
      "0              -0.942857                            0.896825   \n",
      "1              -0.908571                            0.870509   \n",
      "2              -0.880000                            0.849398   \n",
      "3              -0.885714                            0.857266   \n",
      "4              -0.942857                            0.896825   \n",
      "...                  ...                                 ...   \n",
      "1695           -0.914286                            0.846093   \n",
      "1696           -0.942857                            0.968254   \n",
      "1697           -0.942857                            0.957816   \n",
      "1698           -0.931429                            0.927625   \n",
      "1699           -0.925714                            0.921253   \n",
      "\n",
      "      Avg_AbsBias_Male  Avg_Bias_Male  Avg_AbsBias_for_Accurate_Male  \\\n",
      "0             0.542857      -0.028571                       0.588209   \n",
      "1             0.371429       0.108571                       0.420816   \n",
      "2             0.445714       0.171429                       0.492171   \n",
      "3             0.442857       0.231429                       0.499542   \n",
      "4             0.542857      -0.028571                       0.588209   \n",
      "...                ...            ...                            ...   \n",
      "1695          0.354286      -0.354286                       0.471831   \n",
      "1696          0.485714       0.028571                       0.514739   \n",
      "1697          0.302857       0.165714                       0.354251   \n",
      "1698          0.308571       0.205714                       0.306317   \n",
      "1699          0.297143       0.154286                       0.361018   \n",
      "\n",
      "      Avg_AbsBias_Young  Avg_Bias_Young  Avg_AbsBias_for_Accurate_Young  \\\n",
      "0              0.742857        0.514286                        0.765079   \n",
      "1              0.794286        0.531429                        0.815910   \n",
      "2              0.754286        0.491429                        0.763381   \n",
      "3              0.694286        0.442857                        0.699235   \n",
      "4              0.742857        0.514286                        0.765079   \n",
      "...                 ...             ...                             ...   \n",
      "1695           0.608571        0.608571                        0.689837   \n",
      "1696           0.800000        0.514286                        0.837302   \n",
      "1697           0.702857        0.508571                        0.747930   \n",
      "1698           0.685714        0.560000                        0.728402   \n",
      "1699           0.674286        0.560000                        0.718112   \n",
      "\n",
      "      Avg_Max_MC_Bias  Max_AbsBias  \n",
      "0            0.671429     0.942857  \n",
      "1            0.594286     0.908571  \n",
      "2            0.600000     0.880000  \n",
      "3            0.577143     0.885714  \n",
      "4            0.671429     0.942857  \n",
      "...               ...          ...  \n",
      "1695         0.585714     0.914286  \n",
      "1696         0.671429     0.942857  \n",
      "1697         0.548571     0.942857  \n",
      "1698         0.517143     0.931429  \n",
      "1699         0.531429     0.925714  \n",
      "\n",
      "[1700 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "catagories = ['attractive person', 'blurry photo of a person', 'person with brown hair', 'person wearing eyeglasses', 'person with gray hair', 'smiling person', 'person in a hat']\n",
    "catagory_column = ['Attractive', 'Blurry', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Smiling', 'Wearing_Hat']\n",
    "\n",
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "indistinguisable_values = [[\"1\"] for cat in catagory_column]\n",
    "totals_by_cat = {cat: len(data[data[catagory_column[i]] == \"1\"]) for i, cat in enumerate(catagories)}\n",
    "image_database.define_coordinate_mapping(['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']])\n",
    "\n",
    "debias_database = ImageDatabase(features_debias, data, model_debias, preprocess_debias, device_d)\n",
    "\n",
    "image_database.add_clipclip_ordering(\"gender\", np.load('datasets/MI_orders/gender.npy'))\n",
    "image_database.add_clipclip_ordering(\"skintone\", np.load('datasets/MI_orders/skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"age\", np.load('datasets/MI_orders/age.npy'))\n",
    "image_database.add_clipclip_ordering(\"gender_skintone\", np.load('datasets/MI_orders/gender_skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "image_database.add_clipclip_ordering(\"additional_concepts\", np.load('datasets/MI_orders/additional_concepts.npy'))\n",
    "\n",
    "\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_age', [(\"sensitive_attributes\", [(\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_age', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='feature_distances'), 'CDI_Features', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='true_labels'), 'CDI_TrueConcept', []),\n",
    "    \n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_gender', [(\"pbm_classes\", [\"unknown gender\", \"man\", \"woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_intersectional', [(\"pbm_classes\", [\"unknown gender and skin-tone\", \"light-skinned man\", \"light-skinned woman\", \"dark-skinned man\", \"dark-skinned woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_skintone', [(\"pbm_classes\", [\"unknown skin-tone\", \"light-skinned person\", \"dark-skinned person\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_three_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, and gender\", \"\"))]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_four_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"American\", \"non-American\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, nationality, and gender\", \"\"))]),\n",
    "    \n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender\", n, k), 'CLIP_gender', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"skintone\", n, k), 'CLIP_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"age\", n, k), 'CLIP_age', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender_skintone\", n, k), 'CLIP_gender_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"additional_concepts\", n, k), 'CLIP_add_concept', []),\n",
    "\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ks = [10, 25, 50, 100]  # [10, 25, 50, 100] \n",
    "\n",
    "number_of_tol_steps = 16 # 16\n",
    "number_of_eps_steps = 11 # 11\n",
    "number_of_clip_clip_steps = 24 #24\n",
    "random_iters = 4 #4\n",
    "\n",
    "result_dicts = []\n",
    "\n",
    "for method, name, spec in method_name_specification_list:\n",
    "    print(f\"Starting analysis for method: {name}...\")\n",
    "    for s, val in spec:\n",
    "        if s == \"sensitive_attributes\":\n",
    "            image_database.sensitive_attributes(val)\n",
    "        if s == \"pbm_classes\":\n",
    "            image_database.define_pbm_classes(val)\n",
    "    for k in tqdm(ks):\n",
    "        result_dict = {'name': name}\n",
    "\n",
    "        if name in ['Baseline', \"DebiasClip\"]:\n",
    "            steps = 1\n",
    "        else:\n",
    "            steps = number_of_tol_steps\n",
    "\n",
    "        if name[0:3] == 'PBM':\n",
    "            for e in reversed(range(0, number_of_eps_steps)):\n",
    "                eps = e / (number_of_eps_steps - 1)\n",
    "                retrieval_function = method(k, eps)\n",
    "                new_dict = result_dict.copy()\n",
    "                random_results = []\n",
    "                for i in range(random_iters):\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis_celeba(retrieval_function, k, eps, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    random_results.append(new_dict)\n",
    "                \n",
    "                add_dict = result_dict.copy()\n",
    "                for key in random_results[0].keys():\n",
    "                    if key == 'name':\n",
    "                        continue\n",
    "                    add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                result_dicts.append(add_dict)\n",
    "\n",
    "        elif name[0:4] == 'CLIP':\n",
    "            for e in range(0, number_of_clip_clip_steps):\n",
    "                n = e * 20\n",
    "                retrieval_function = method(k, n)\n",
    "                new_dict = result_dict.copy()\n",
    "                run_analysis_celeba(retrieval_function, k, n, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "        else:\n",
    "            for t in range(0, steps):\n",
    "                if steps == 1:\n",
    "                    tol = None\n",
    "                else:\n",
    "                    tol = t / 200\n",
    "                retrieval_function = method(k, tol)\n",
    "                new_dict = result_dict.copy()\n",
    "                if name == \"CDI_Random\":\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    new_dict = result_dict.copy()\n",
    "\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                else:\n",
    "                    run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis_celeba(result_dicts, ['Pale_Skin', 'Male', 'Young'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_pickle(\"results/celeba-3-24.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    }
   ],
   "source": [
    "res = image_database.search(\"A picture of an attractive person\")\n",
    "\n",
    "print(multiclass_bias_in_retrieval('Attractive', [\"1\"], res, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']] ))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
