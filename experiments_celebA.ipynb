{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import clip\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from image_database import *\n",
    "from PIL import Image\n",
    "from scipy.spatial.distance import cdist\n",
    "import bisect \n",
    "from scipy.spatial import ConvexHull\n",
    "import gc\n",
    "import debias_clip as dclip\n",
    "#import cvxpy as cp\n",
    "image_folder_prefix = 'datasets/celeba/img_align_celeba/'\n",
    "\n",
    "data = pd.read_csv('datasets/celeba/alg_testing.csv') #datasets\\occuptations_2\\occupations_labels.csv\n",
    "data = data.astype('string')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[data['Pale_Skin'] == '1'].head())\n",
    "\n",
    "for image_loc in data[data['Pale_Skin'] == '-1']['image_id']:\n",
    "    image = Image.open(image_folder_prefix + image_loc)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.load('datasets/celeba/features.npy')[20000:35000]\n",
    "\n",
    "features_debias = np.load('datasets/celeba/features_debias.npy')[20000:35000]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_d = 'cpu'\n",
    "model_debias, preprocess_debias = dclip.load(\"ViT-B/16-gender\", device_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['5_o_Clock_Shadow'])\n",
    "data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catagories = ['attractive person', 'blurry photo of a person', 'person with brown hair', 'person wearing eyeglasses', 'person with gray hair', 'smiling person', 'person in a hat']\n",
    "catagory_column = ['Attractive', 'Blurry', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Smiling', 'Wearing_Hat']\n",
    "\n",
    "image_database = ImageDatabase(features, data, model, preprocess, device)\n",
    "indistinguisable_values = [[\"1\"] for cat in catagory_column]\n",
    "totals_by_cat = {cat: len(data[data[catagory_column[i]] == \"1\"]) for i, cat in enumerate(catagories)}\n",
    "image_database.define_coordinate_mapping(['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']])\n",
    "\n",
    "debias_database = ImageDatabase(features_debias, data, model_debias, preprocess_debias, device_d)\n",
    "\n",
    "image_database.add_clipclip_ordering(\"gender\", np.load('datasets/MI_orders/gender.npy'))\n",
    "image_database.add_clipclip_ordering(\"skintone\", np.load('datasets/MI_orders/skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"age\", np.load('datasets/MI_orders/age.npy'))\n",
    "image_database.add_clipclip_ordering(\"gender_skintone\", np.load('datasets/MI_orders/gender_skintone.npy'))\n",
    "image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "image_database.add_clipclip_ordering(\"additional_concepts\", np.load('datasets/MI_orders/additional_concepts.npy'))\n",
    "\n",
    "\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_age', [(\"sensitive_attributes\", [(\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_gender_skintone', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_skintone', [(\"sensitive_attributes\", [(\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_age', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_4_attr', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a light-skinned person\", \"A picture of a dark-skinned person\"), (\"A picture of an old person\", \"A picture of a young person\"), (\"A picture of an American person\", \"A picture of a non-American person\")])]),\n",
    "\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='feature_distances'), 'CDI_Features', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='true_labels'), 'CDI_TrueConcept', []),\n",
    "    \n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_gender', [(\"pbm_classes\", [\"unknown gender\", \"man\", \"woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_intersectional', [(\"pbm_classes\", [\"unknown gender and skin-tone\", \"light-skinned man\", \"light-skinned woman\", \"dark-skinned man\", \"dark-skinned woman\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_skintone', [(\"pbm_classes\", [\"unknown skin-tone\", \"light-skinned person\", \"dark-skinned person\"])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_three_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, and gender\", \"\"))]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_four_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"light-skinned\", \"dark-skinned\"], [\"old\", \"young\"], [\"American\", \"non-American\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, nationality, and gender\", \"\"))]),\n",
    "    \n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender\", n, k), 'CLIP_gender', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"skintone\", n, k), 'CLIP_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"age\", n, k), 'CLIP_age', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"gender_skintone\", n, k), 'CLIP_gender_skintone', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"additional_concepts\", n, k), 'CLIP_add_concept', []),\n",
    "\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\n",
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='random'), 'CDI_Random', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\")])]),\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "ks = [10, 25, 50, 100]  # [10, 25, 50, 100] \n",
    "\n",
    "number_of_tol_steps = 16 # 16\n",
    "number_of_eps_steps = 11 # 11\n",
    "number_of_clip_clip_steps = 24 #24\n",
    "random_iters = 4 #4\n",
    "\n",
    "result_dicts = []\n",
    "\n",
    "for method, name, spec in method_name_specification_list:\n",
    "    print(f\"Starting analysis for method: {name}...\")\n",
    "    for s, val in spec:\n",
    "        if s == \"sensitive_attributes\":\n",
    "            image_database.sensitive_attributes(val)\n",
    "        if s == \"pbm_classes\":\n",
    "            image_database.define_pbm_classes(val)\n",
    "    for k in tqdm(ks):\n",
    "        result_dict = {'name': name}\n",
    "\n",
    "        if name in ['Baseline', \"DebiasClip\"]:\n",
    "            steps = 1\n",
    "        else:\n",
    "            steps = number_of_tol_steps\n",
    "\n",
    "        if name[0:3] == 'PBM':\n",
    "            for e in reversed(range(0, number_of_eps_steps)):\n",
    "                eps = e / (number_of_eps_steps - 1)\n",
    "                retrieval_function = method(k, eps)\n",
    "                new_dict = result_dict.copy()\n",
    "                random_results = []\n",
    "                for i in range(random_iters):\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis_celeba(retrieval_function, k, eps, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    random_results.append(new_dict)\n",
    "                \n",
    "                add_dict = result_dict.copy()\n",
    "                for key in random_results[0].keys():\n",
    "                    if key == 'name':\n",
    "                        continue\n",
    "                    add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                result_dicts.append(add_dict)\n",
    "\n",
    "        elif name[0:4] == 'CLIP':\n",
    "            for e in range(0, number_of_clip_clip_steps):\n",
    "                n = e * 20\n",
    "                retrieval_function = method(k, n)\n",
    "                new_dict = result_dict.copy()\n",
    "                run_analysis_celeba(retrieval_function, k, n, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "        else:\n",
    "            for t in range(0, steps):\n",
    "                if steps == 1:\n",
    "                    tol = None\n",
    "                else:\n",
    "                    tol = t / 200\n",
    "                retrieval_function = method(k, tol)\n",
    "                new_dict = result_dict.copy()\n",
    "                if name == \"CDI_Random\":\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    new_dict = result_dict.copy()\n",
    "\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                else:\n",
    "                    run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis_celeba(result_dicts, ['Pale_Skin', 'Male', 'Young'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_pickle(\"results/celeba-random.pkl\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"results/celeba-3-24.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "method_name_specification_list = [\n",
    "    (lambda k, tol: lambda x: image_database.search(x, k), 'Baseline', []),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_sum'), 'CDI_Sum_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a white person\", \"A picture of a non-white person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, tol: lambda x: image_database.distinct_retrival(x, k, tol=tol, method='max_min'), 'CDI_Min_intersectional', [(\"sensitive_attributes\", [(\"A picture of a man\", \"A picture of a woman\"), (\"A picture of a white person\", \"A picture of a non-white person\"), (\"A picture of an old person\", \"A picture of a young person\")])]),\n",
    "    (lambda k, eps: lambda x: image_database.pbm(x, k, eps=eps), 'PBM_three_attributes', [(\"pbm_classes\", intersections_for_pbm([[\"white\", \"non-white\"], [\"old\", \"young\"], [\"man\", \"woman\"]], \"an unknown skin-tone, age, and gender\", \"\"))]),\n",
    "    (lambda k, n: lambda x: image_database.clip_clip(x, \"intersectional\", n, k), 'CLIP_intersectional', []),\n",
    "    (lambda k, tol: lambda x: debias_database.search(x, k), 'DebiasClip', [])\n",
    "]\n",
    "np.random.seed(123)\n",
    "\n",
    "catagories = ['attractive person', 'blurry photo of a person', 'person with brown hair', 'person wearing eyeglasses', 'person with gray hair', 'smiling person', 'person in a hat']\n",
    "catagory_column = ['Attractive', 'Blurry', 'Brown_Hair', 'Eyeglasses', 'Gray_Hair', 'Smiling', 'Wearing_Hat']\n",
    "\n",
    "features = np.load('datasets/celeba/features.npy')\n",
    "features_debias = np.load('datasets/celeba/features_debias.npy')\n",
    "\n",
    "data = pd.read_csv('datasets/celeba/list_attr_celeba.csv')\n",
    "data = data.astype('string')\n",
    "\n",
    "start_idx = 20000\n",
    "step_idx = 15000\n",
    "\n",
    "result_dicts = []\n",
    "for runs in range(5):\n",
    "    lb = start_idx + runs * step_idx\n",
    "    ub = start_idx + (runs + 1) * step_idx\n",
    "    f_random = features[lb:ub]\n",
    "    d_random = data.iloc[lb:ub]\n",
    "    fd_random = features_debias[lb:ub]\n",
    "    image_database = ImageDatabase(f_random, d_random, model, preprocess, device)\n",
    "    indistinguisable_values = [[\"1\"] for cat in catagory_column]\n",
    "    totals_by_cat = {cat: len(data[data[catagory_column[i]] == \"1\"]) for i, cat in enumerate(catagories)}\n",
    "    image_database.define_coordinate_mapping(['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']])\n",
    "    \n",
    "    debias_database = ImageDatabase(fd_random, d_random, model_debias, preprocess_debias, device_d)\n",
    "    image_database.add_clipclip_ordering(\"intersectional\", np.load('datasets/MI_orders/intersectional.npy'))\n",
    "\n",
    "    ks = [10, 25, 50, 100] # [10, 25, 50, 100] \n",
    "\n",
    "    number_of_tol_steps = 16 # 16\n",
    "    number_of_eps_steps = 11 # 11\n",
    "    number_of_clip_clip_steps = 24 #24\n",
    "    random_iters = 4 #4\n",
    "\n",
    "    for method, name, spec in method_name_specification_list:\n",
    "        print(f\"Starting analysis for method: {name}...\")\n",
    "        for s, val in spec:\n",
    "            if s == \"sensitive_attributes\":\n",
    "                image_database.sensitive_attributes(val)\n",
    "            if s == \"pbm_classes\":\n",
    "                image_database.define_pbm_classes(val)\n",
    "        for k in tqdm(ks):\n",
    "            result_dict = {'name': name}\n",
    "\n",
    "            if name in ['Baseline', \"DebiasClip\"]:\n",
    "                steps = 1\n",
    "            else:\n",
    "                steps = number_of_tol_steps\n",
    "\n",
    "            if name[0:3] == 'PBM':\n",
    "                for e in reversed(range(0, number_of_eps_steps)):\n",
    "                    eps = e / (number_of_eps_steps - 1)\n",
    "                    retrieval_function = method(k, eps)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    random_results = []\n",
    "                    for i in range(random_iters):\n",
    "                        new_dict = result_dict.copy()\n",
    "                        run_analysis_celeba(retrieval_function, k, eps, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                        random_results.append(new_dict)\n",
    "                    \n",
    "                    add_dict = result_dict.copy()\n",
    "                    for key in random_results[0].keys():\n",
    "                        if key == 'name':\n",
    "                            continue\n",
    "                        add_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                    result_dicts.append(add_dict)\n",
    "\n",
    "            elif name[0:4] == 'CLIP':\n",
    "                for e in range(0, number_of_clip_clip_steps):\n",
    "                    n = e * 20\n",
    "                    retrieval_function = method(k, n)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    run_analysis_celeba(retrieval_function, k, n, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    result_dicts.append(new_dict)\n",
    "            else:\n",
    "                for t in range(0, steps):\n",
    "                    if steps == 1:\n",
    "                        tol = None\n",
    "                    else:\n",
    "                        tol = t / 200\n",
    "                    retrieval_function = method(k, tol)\n",
    "                    new_dict = result_dict.copy()\n",
    "                    if name == \"CDI_Random\":\n",
    "                        random_results = []\n",
    "                        for i in range(random_iters):\n",
    "                            new_dict = result_dict.copy()\n",
    "                            run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                            random_results.append(new_dict)\n",
    "                        new_dict = result_dict.copy()\n",
    "\n",
    "                        for key in random_results[0].keys():\n",
    "                            if key == 'name':\n",
    "                                continue\n",
    "                            new_dict[key] = np.mean([res[key] for res in random_results], axis=0)\n",
    "                    else:\n",
    "                        run_analysis_celeba(retrieval_function, k, tol, new_dict, catagories, catagory_column, indistinguisable_values, ['Pale_Skin', 'Male', 'Young'], [['1'], ['1'], ['1']], [['-1'], ['-1'], ['-1']], totals_by_cat)\n",
    "                    result_dicts.append(new_dict)\n",
    "\n",
    "df = parse_analysis_celeba(result_dicts, ['Pale_Skin', 'Male', 'Young'])\n",
    "\n",
    "df.to_pickle(\"results/celeba-validation-white-nonwhite.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
